{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2c7ca4-0c0f-41c9-8cf1-058560e2f5bd",
   "metadata": {},
   "source": [
    "# BIGQUERY TO SNOWFLAKE SCHEMA CONVERSION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce4367-04b9-4b82-9b15-5c4855899f8a",
   "metadata": {},
   "source": [
    "### 1. CREATE SNOWFLAKE DDL SCRIPT FROM JSON SCHEMA FILES\n",
    "### 2. EXECUTE SCRIPTS TO CREATE TABLES\n",
    "### 3. PUT DATA FILES INTO INTERNAL STAGE\n",
    "### 4. COPY DATA FILES FROM INTERNAL STAGE TO SNOWFLAKE TABLES\n",
    "### 5. VALIDATE SUCCESS AND FAILED LOADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a031d3-00bf-410b-9401-c102a3225159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import avg, sum, col,lit\n",
    "from snowflake.snowpark.functions import udf, sproc, col\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, LongType, DoubleType, DecimalType,StringType, BooleanType, Variant\n",
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "from snowflake.snowpark import functions as fn\n",
    "\n",
    "import sys ,json\n",
    "import io\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from snowflake.snowpark import version\n",
    "print (f\"snowflake snowpark version is: {version.VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769a730-2be5-42a1-9c17-e14949282fd5",
   "metadata": {},
   "source": [
    "### Install glob2 if not installed already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d5903-7646-4ef4-a489-a24b036a764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install glob2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7667d0-b244-45ff-9004-1c8f7d8e6b39",
   "metadata": {},
   "source": [
    "### Create the scripts from the provided schema json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7a714-2382-4d31-aab8-53f9abb689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = []\n",
    "from glob2 import glob\n",
    "scriptfiles = glob('schema_files/*.json')\n",
    "for j in scriptfiles:\n",
    "# j = 'schema_files/affinity_api_weekly_dma_brand_channel_panel_schema.json'\n",
    "    try:\n",
    "        table = j.split('/')[-1].split('.')[0].replace('_schema','')\n",
    "        f = open(j)\n",
    "        data = json.load(f)\n",
    "        col = []\n",
    "        table_create = [f\"create or replace table {table} (\"]\n",
    "        for i in range(len(data)):\n",
    "            dtype = data[i]['type']\n",
    "            if data[i]['type'] == 'BIGNUMERIC': ##not supported in snowflake\n",
    "                dtype = 'NUMBER'\n",
    "            if i<len(data)-1:\n",
    "                table_create+=[data[i]['name']+' '+dtype]+[',']\n",
    "            else:\n",
    "                table_create+=[data[i]['name']+' '+dtype]        \n",
    "        table_create+=[')']    \n",
    "        script+=[''.join([i for i in table_create])]\n",
    "    except:\n",
    "        print (f\"cannot create dml script for '{j}' , please check if valid file\")\n",
    "print (f\"total files read : {len(scriptfiles)}\")\n",
    "print (f\"total scripts generated : {len(script)}\")\n",
    "print (f\"invalid files : {len(scriptfiles) - len(script)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c137b-6d94-4347-954d-6593242f2900",
   "metadata": {},
   "source": [
    "### Connect to the snowflake session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da039389-d76b-4fa1-b0d0-f8309de11dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_connection_cfg = open('cred.json')\n",
    "snowflake_connection_cfg = snowflake_connection_cfg.read()\n",
    "snowflake_connection_cfg = json.loads(snowflake_connection_cfg)\n",
    "\n",
    "# Creating Snowpark Session\n",
    "load_session = Session.builder.configs(snowflake_connection_cfg).create()\n",
    "print('Current Database:', load_session.get_current_database())\n",
    "print('Current Schema:', load_session.get_current_schema())\n",
    "print('Current Warehouse:', load_session.get_current_warehouse())\n",
    "print(\"Warehouse set up:\")\n",
    "load_session.sql(\"show warehouses like 'APP_WH'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2179c3ab-75ed-459b-8604-832a73d55446",
   "metadata": {},
   "source": [
    "### Create tables in snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f576178-60ae-49ce-8971-8387aec80de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in script:\n",
    "    try:\n",
    "        load_session.sql(s).collect()\n",
    "    except:\n",
    "        print (f\"cannot create table for dml script , please check if script is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c00cb-b6fa-4f14-aee3-a6fad27678f8",
   "metadata": {},
   "source": [
    "### PUT the data files from your local folder into snowflake internal stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed81d50-ba05-4ad6-9194-f39318e970c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_session.sql(\"CREATE OR REPLACE STAGE stage_data\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a872a3-9cc8-49bb-90c3-6dcadf4a7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = glob('data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce92370-3cee-4ade-9d20-1aba27bf4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in datafiles:\n",
    "    try:\n",
    "        load_session.file.put(c, 'stage_data')\n",
    "    except:\n",
    "        print (f\"cannot load file {c}\")\n",
    "print (f\"total number of data file available : {len(datafiles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16529c3-759f-41bc-88c8-eb64f657a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_stage_list = load_session.sql(\"list @stage_data\").collect()\n",
    "print (f\"total number of data file available : {len(internal_stage_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb919e4e-ddc5-4e47-8f10-f26f2ae9867e",
   "metadata": {},
   "source": [
    "### Load Data to Snowflake from internal stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20969d-e371-486e-9b7c-6931b3f7c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_script = []\n",
    "loads_failed = []\n",
    "loads_success = []\n",
    "stage_directory = 'stage_data'\n",
    "for d in datafiles:\n",
    "    copy = f\"copy into {d.split('/')[-1].split('.')[0].replace('synthetic_data_','')}\\\n",
    "     from @{stage_directory}/{d.split('/')[-1].split('.')[0]}.csv.gz \"\n",
    "    form = '''FILE_FORMAT = (TYPE = 'csv' RECORD_DELIMITER = '\\\\n' SKIP_HEADER = 1 field_optionally_enclosed_by='\"' DATE_FORMAT = 'YYYY-MM-DD')'''\n",
    "    try:\n",
    "        load_session.sql(copy+form).collect()\n",
    "        loads_success.append(d)\n",
    "    except:\n",
    "        loads_failed.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680e693-f403-45e1-8d8c-9c4ddfde7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_failed ### take action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04482c4b-6775-4056-b9b1-90acc6b323ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_success ### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799752f2-36d7-411d-b98b-09f717f202ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_still_failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c16e9c-e5d7-45dc-afa5-d9c62703e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in loads_failed:\n",
    "    df = pd.read_csv(f)\n",
    "    table_name = f.replace('Synthetic data/synthetic_data_','').split('.')[0]\n",
    "    try:\n",
    "        load_session.create_dataframe(df)\\\n",
    "        .write.mode(\"append\")\\\n",
    "        .save_as_table(table_name)\n",
    "    except:\n",
    "        loads_still_failed.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dcce24-5ebd-40e3-b5c1-0ca3d1d8e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_still_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4ec20-2d8c-467a-beee-eba2cca7afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_session.close()\n",
    "print('Finished!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8874cd-764f-4327-b0f0-ab4c2badc056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
